#导入探索性数据分析所需要的包
import pandas as pd #存储数据表格
import numpy as np #数学计算包
import matplotlib.pyplot as plt #流行的数据可视化工具
import seaborn as sns #另一个流行的数据可视化工具
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import Imputer
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import Normalizer

plt.style.use('fivethirtyeight')#流行的数据可视化主题

#使用pandas导入数据
pima_column_name=['time_pregnant','plasma_glucose_concentration',
                  'diastolic_blood_pressure','triceps_thickness','serum_insulin',
                  'bmi','pedigree_function','age','onset_diabetes']#加列名
pima=pd.read_csv('pima_data.csv',names=pima_column_name)
#print(pima.head())

#计算一下空准确率(模型预测频率较高时候的准确率)
P=pima['onset_diabetes'].value_counts(normalize=True)
#print(P)

#对plasma_glucose_concentration列绘制两类的直方图

'''
for col in ['bmi','diastolic_blood_pressure','plasma_glucose_concentration']:
    plt.hist(pima[pima['onset_diabetes']==0][col],10,alpha=0.5,label='non-diabetes')
    plt.hist(pima[pima['onset_diabetes']==1][col],10,alpha=0.5,label='diabetes')
    plt.legend(loc='upper right')
    plt.xlabel(col)
    plt.ylabel('Frequency')
    plt.title('Histogram of {}'.format(col))
    plt.show()
'''
#看来三者指标关系与是否患病关系很大，现在用一开始导入的season库，用线性相关矩阵来描述这样的关系
#数据集相关矩阵的热力图
#sns.heatmap(pima.corr())
#plt.show()

#这个葡萄糖浓度和糖尿病关系很大，下面进一步研究各列之间的相关性
#print(pima.corr()['onset_diabetes'])

#判断是否有缺失值，这点非常重要！
#print(pima.isnull().sum())

#很好没有缺失值，用shape方法去看看数据的列数和行数
#print(pima.shape)

#然后看看糖尿病的发病率
#print(pima['onset_diabetes'].value_counts(normalize=True))

#65%的人没有糖尿病，35%的人有糖尿病。可以yonDataFrame内置的describe方法提供基本的数据描述
#print(pima.describe())

#表格里面有基本的统计量，例如均值，标准差，以及一些百分位数据。但是，BMI的平均值为0，这是有悖医学常识的，也许数据中缺失或不存在的点都用0填充了。
#我们发现有些值缺失但是用0填充了。

#我们发现有5列存在缺失值，现在来深入研究如何处理这个问题


#被错误填充的缺失值是0
#print(pima['serum_insulin'].isnull().sum())

#手动用None替换0
#pima['serum_insulin']=pima['serum_insulin'].map(lambda x:x if x != 0 else None)

#检查缺失值
#print(pima['serum_insulin'].isnull().sum())

#直接对所有列的数据进行操作，将所有的列缺失值换出来
columns=['plasma_glucose_concentration','diastolic_blood_pressure','triceps_thickness','serum_insulin','bmi']

for col in columns:
    pima[col].replace([0],[None],inplace=True)

#用isnull方法去计算缺失值数量
pima.isnull().sum()

#进行一些描述性统计
# print(pima.describe())

#取均值和标准差
#print(pima['plasma_glucose_concentration'].mean(),pima['plasma_glucose_concentration'].std())

#删除存在缺失值的行
pima_dropped=pima.dropna()

num_rows_lost=round(100*(pima.shape[0]-pima_dropped.shape[0])/float(pima.shape[0]))
#print("retained {}% of rows".format(num_rows_lost))

#丢弃缺失值前后的探索性数据分析

#分成True和False两组
#print(pima['onset_diabetes'].value_counts(normalize=True))

#每列的均值（不算缺失值）
#print(pima.mean())
#每列的均值（删缺失值）
#print(pima_dropped.mean())

#均值变化百分比
#print((pima_dropped.mean()-pima.mean())/pima.mean())

'''
#用条形图可视化
ax=((pima_dropped.mean()-pima.mean())/pima.mean()).plot(kind='bar',title='%change in average column values')
ax.set_ylabel('% change')
plt.show()
'''
#删除行会严重影响数据的形状，这个案例中不建议删除行，应该保留更多数据。

#这里开始机器学习

#注意使用删除缺失值之后的数据

'''
X_dropped=pima_dropped.drop('onset_diabetes',axis=1)
#删除响应变量，建立特征矩阵
print("learning from {} rows".format(X_dropped.shape[0]))
y_dropped=pima_dropped['onset_diabetes']

#网格搜索所需的变量实例。网络搜索可以找到最适合我们模型的、交叉验证率最好的KNN参数组合

#需要试验的KNN模型参数
knn_params={'n_neighbors':[1,2,3,4,5,6,7]}

knn=KNeighborsClassifier()#设置knn模型

grid=GridSearchCV(knn,knn_params)
grid.fit(X_dropped,y_dropped)

print(grid.best_score_,grid.best_params_)
#但是我们只是研究很少行
'''
#这样的话最好的邻居为7个,knn模型的正确率为74.5%,比空正确率要好。

#用剩下列的均值去填充缺失值

#填充血浆列
#print(pima.isnull().sum())

#看一下plasma_glucose_concentration列那5个缺失值
empty_plasma_index=pima[pima['plasma_glucose_concentration'].isnull()].index
#print(pima.loc[empty_plasma_index]['plasma_glucose_concentration'])

#pima['plasma_glucose_concentration'].fillna(pima['plasma_glucose_concentration'].mean(),inplace=True)
#print(pima.isnull().sum())

#print(pima.loc[empty_plasma_index]['plasma_glucose_concentration'])

#使用sklearn的Imputer模块
imputer=Imputer(strategy='mean')

#调用fit_transform方法创建新对象
pima_imputed=imputer.fit_transform(pima)

#Imputer输出值不是Pandas的DataFrame类型的数据，而是Numpy的数组
#这里需要用DataFrame方法转为数组
pima_imputed=pd.DataFrame(pima_imputed,columns=pima_column_name)

#看新的DataFrame
#print(pima_imputed.head())

#找下plasma_glucose_concentration列，应该是和原来的填充相同。
#print(pima_imputed.loc[empty_plasma_index]['plasma_glucose_concentration'])

#最后再检查一下，DataFrame不应该有缺失值
#print(pima_imputed.isnull().sum())

'''
pima_zero=pima.fillna(0)#用0填充
X_zero=pima_zero.drop('onset_diabetes',axis=1)
print("learning from {} rows".format(X_zero.shape[0]))
y_zero=pima_zero['onset_diabetes']

knn_parems={'n_neighbors':[1,2,3,4,5,6,7]}
knn=KNeighborsClassifier()#设置knn模型

grid=GridSearchCV(knn,knn_parems)
grid.fit(X_zero,y_zero)

print(grid.best_score_,grid.best_params_)#用0填充比用均值填充准确率下降
'''

'''
#复制一份数据集
X=pima[['serum_insulin']].copy()
y=pima['onset_diabetes'].copy()

#使用相同的随机状态
X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=99)
#print(X.isnull().sum())

#此时用训练集的均值去填充缺失值

training_mean=X_train.mean()
X_train=X_train.fillna(training_mean)
X_test=X_test.fillna(training_mean)

#print(training_mean)

#同个数据集正确填充值的KNN模型打分

knn=KNeighborsClassifier()
knn.fit(X_train,y_train)
#print(knn.score(X_test,y_test))


#必须重新定义参数以符合流水线
knn_params={'classify__n_neighbors':[1,2,3,4,5,6,7]}

knn=KNeighborsClassifier()

median_impute = Pipeline([('imputer', Imputer(strategy='median')), ('classify', knn)])
X = pima.drop('onset_diabetes',axis=1)
y = pima['onset_diabetes']

grid = GridSearchCV(median_impute, knn_params)

grid.fit(X, y)

#print(grid.best_score_,grid.best_params_)



#填充所有缺失值
impute=Imputer(strategy='mean')

pima_imputed_mean=pd.DataFrame(imputer.fit_transform(pima),columns=pima_column_name)
pima_imputed_mean.hist(figsize=(15,15),sharex=True)
#plt.show()

#print(pima_imputed_mean.describe())
#print(pima['plasma_glucose_concentration'].head())

#print(pima['plasma_glucose_concention'.mean()])
#print(pima['plasma_glucose_concention'.std()])

#取此列的均值
mu=pima['plasma_glucose_concentration'].mean()

#取此列的标准差
sigma=pima['plasma_glucose_concentration'].std()

#对每个值计算z分数
print(((pima['plasma_glucose_concentration']-mu)/sigma).head())

#内置的分数归一化
scaler=StandardScaler()
glucose_z_score_standardized=scaler.fit_transform(pima[['plasma_glucose_concentration']])
#双括号，因为转化类型为DataFrame

#均值是0，标准差是1
print(glucose_z_score_standardized.mean(),glucose_z_score_standardized.std())
'''

'''
min_max=MinMaxScaler()

pima_min_max=pd.DataFrame(min_max.fit_transform(pima_imputed),columns=pima_column_name)
#print(pima_min_max.describe())

knn=KNeighborsClassifier()
knn_params={'imputer__strategy':['mean','median'],'classify__n_neighbors':[1,2,3,4,5,6,7]}
mean_impute_standardize=Pipeline([('imputer',Imputer()),('standardize',MinMaxScaler()),('classify',knn)])

X=pima_min_max.drop('onset_diabetes',axis=1)

y=pima['onset_diabetes']

grid=GridSearchCV(mean_impute_standardize,knn_params)
grid.fit(X,y)

print(grid.best_score_,grid.best_params_)
'''

'''
#print(np.sqrt(pima_imputed**2).sum(axis=1).mean())

normalize=Normalizer()

pima_normalized=pd.DataFrame(normalize.fit_transform(pima_imputed),columns=pima_column_name)

#行归一化之后的矩阵平均范数
print(np.sqrt((pima_normalized**2).sum(axis=1).mean()))
'''
